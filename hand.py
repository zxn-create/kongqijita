import cv2
import mediapipe as mp
import numpy as np
import time

class AirGuitarGestureRecognizer:
    def __init__(self):
        """åˆå§‹åŒ–MediaPipeæ‰‹åŠ¿è¯†åˆ«å™¨"""
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=2,  # æ£€æµ‹ä¸¤åªæ‰‹
            min_detection_confidence=0.7,
            min_tracking_confidence=0.7
        )
        self.mp_drawing = mp.solutions.drawing_utils
        
        # æ‰‹åŠ¿çŠ¶æ€
        self.left_hand_strings = []  # å·¦æ‰‹é€‰æ‹©çš„å¼¦åˆ—è¡¨
        self.right_hand_fret = 0     # å³æ‰‹é€‰æ‹©çš„å“
        self.volume = 0.5           # éŸ³é‡ (0-1)
        
        # æ§åˆ¶çŠ¶æ€
        self.is_recording = False   # æ˜¯å¦å¼€å§‹å½•åˆ¶
        self.hand_positions = {}    # å­˜å‚¨æ‰‹éƒ¨ä½ç½®ç”¨äºæ£€æµ‹ä¸Šä¸‹ç§»åŠ¨
        
    def get_finger_state(self, landmarks, finger_tip_idx, finger_pip_idx, finger_mcp_idx, wrist_idx):
        """åˆ¤æ–­å•ä¸ªæ‰‹æŒ‡æ˜¯å¦ä¼¸ç›´"""
        tip = landmarks[finger_tip_idx]
        pip = landmarks[finger_pip_idx]
        mcp = landmarks[finger_mcp_idx]
        wrist = landmarks[wrist_idx]
        
        # æ–¹æ³•1: è®¡ç®—æŒ‡å°–ä¸æŒ‡å…³èŠ‚çš„è·ç¦»æ¯”
        tip_to_wrist = np.linalg.norm(np.array([tip.x, tip.y]) - np.array([wrist.x, wrist.y]))
        pip_to_wrist = np.linalg.norm(np.array([pip.x, pip.y]) - np.array([wrist.x, wrist.y]))
        
        # æ–¹æ³•2: æ£€æŸ¥æŒ‡å°–æ˜¯å¦åœ¨æŒ‡å…³èŠ‚ä¹‹ä¸Šï¼ˆé’ˆå¯¹ç«–å‘æ‰‹åŠ¿ï¼‰
        # å›¾åƒåæ ‡yè½´å‘ä¸‹ï¼Œæ‰€ä»¥yå€¼è¶Šå°è¡¨ç¤ºè¶Šé«˜
        is_extended_by_y = tip.y < pip.y - 0.02
        
        # æ–¹æ³•3: è®¡ç®—è§’åº¦ï¼ˆæ›´å‡†ç¡®ï¼‰
        # ä½¿ç”¨ä¸‰ä¸ªç‚¹è®¡ç®—è§’åº¦ï¼šMCP -> PIP -> TIP
        vector1 = np.array([pip.x - mcp.x, pip.y - mcp.y])
        vector2 = np.array([tip.x - pip.x, tip.y - pip.y])
        
        if np.linalg.norm(vector1) == 0 or np.linalg.norm(vector2) == 0:
            return False
            
        # è®¡ç®—ä½™å¼¦å€¼
        cos_angle = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))
        angle = np.degrees(np.arccos(np.clip(cos_angle, -1.0, 1.0)))
        
        # è§’åº¦å°äº160åº¦é€šå¸¸è¡¨ç¤ºå¼¯æ›²
        is_extended_by_angle = angle > 155

        # è·ç¦»æ¯”çº¦æŸï¼šæŒ‡å°–åˆ°è…•çš„è·ç¦»åº”æ˜æ˜¾å¤§äº pip åˆ°è…•çš„è·ç¦»ï¼ˆé¿å…è¿‘æ™¯è¯¯åˆ¤ï¼‰
        dist_ratio = tip_to_wrist / (pip_to_wrist + 1e-6)

        # å¯¹æ‹‡æŒ‡é‡‡ç”¨ä¸“ç”¨åˆ¤å®šï¼šæ‹‡æŒ‡çš„ä¼¸å±•é€šå¸¸æ²¿æŒå®½æ–¹å‘
        if finger_tip_idx == 4:
            try:
                index_mcp = landmarks[5]
                pinky_mcp = landmarks[17]
                palm_width_vec = np.array([pinky_mcp.x - index_mcp.x, pinky_mcp.y - index_mcp.y])
                pw_norm = np.linalg.norm(palm_width_vec)
                if pw_norm > 1e-6:
                    palm_width_unit = palm_width_vec / pw_norm
                else:
                    palm_width_unit = np.array([1.0, 0.0])

                tip_vec = np.array([tip.x - wrist.x, tip.y - wrist.y])
                ip_vec = np.array([pip.x - wrist.x, pip.y - wrist.y])
                proj_tip = np.dot(tip_vec, palm_width_unit)
                proj_ip = np.dot(ip_vec, palm_width_unit)
                # MCP åˆ°è…•çš„è·ç¦»ç”¨äºè¾…åŠ©åˆ¤æ–­ï¼Œé¿å…è¿‘æ™¯æˆ–å™ªå£°å¯¼è‡´çš„è¯¯åˆ¤
                mcp_to_wrist = np.linalg.norm(np.array([mcp.x - wrist.x, mcp.y - wrist.y]))
                # æ›´ä¸¥æ ¼çš„ç»„åˆæ¡ä»¶ï¼šè¦æ±‚æŠ•å½±å·®æ˜¾è‘—ä¸”æŒ‡å°–æ¯” MCP æ›´è¿œï¼Œæˆ–è§’åº¦ä¸è·ç¦»æ¯”åŒæ—¶æ»¡è¶³
                proj_diff = abs(proj_tip) - abs(proj_ip)
                cond_proj = proj_diff > 0.03 and dist_ratio > 0.8 and (tip_to_wrist > mcp_to_wrist * 0.9)
                cond_angle = is_extended_by_angle and dist_ratio > 0.75
                thumb_ok = bool(cond_proj or cond_angle)
            except Exception:
                thumb_ok = (is_extended_by_angle or is_extended_by_y) and (dist_ratio > 0.7)

            return bool(thumb_ok)

        # å¯¹æ— åæŒ‡æ”¾å®½è·ç¦»æ¯”é˜ˆå€¼ï¼Œæå‡åœ¨æŸäº›è§’åº¦ä¸‹çš„è¯†åˆ«ç‡
        if finger_tip_idx == 16:
            dist_thresh = 0.75
        else:
            dist_thresh = 0.85

        # ç»¼åˆåˆ¤æ–­ï¼šå…è®¸è§’åº¦æˆ–é«˜åº¦æˆç«‹ï¼ŒåŒæ—¶æ»¡è¶³ä¸€å®šçš„è·ç¦»æ¯”
        is_extended = (is_extended_by_angle or is_extended_by_y) and (dist_ratio > dist_thresh)

        return bool(is_extended)
    
    def detect_left_hand_strings(self, landmarks):
        """æ£€æµ‹å·¦æ‰‹æ‰‹åŠ¿ï¼Œè¿”å›é€‰æ‹©çš„å¼¦åˆ—è¡¨"""
        strings = []
        
        # MediaPipeæ‰‹éƒ¨å…³é”®ç‚¹ç´¢å¼•
        # æ‹‡æŒ‡: 4(æŒ‡å°–), 3(ç¬¬äºŒå…³èŠ‚), 2(ç¬¬ä¸€å…³èŠ‚), 1(æ ¹éƒ¨)
        # é£ŸæŒ‡: 8(æŒ‡å°–), 7(ç¬¬ä¸‰å…³èŠ‚), 6(ç¬¬äºŒå…³èŠ‚), 5(æ ¹éƒ¨)
        # ä¸­æŒ‡: 12(æŒ‡å°–), 11(ç¬¬ä¸‰å…³èŠ‚), 10(ç¬¬äºŒå…³èŠ‚), 9(æ ¹éƒ¨)
        # æ— åæŒ‡: 16(æŒ‡å°–), 15(ç¬¬ä¸‰å…³èŠ‚), 14(ç¬¬äºŒå…³èŠ‚), 13(æ ¹éƒ¨)
        # å°æŒ‡: 20(æŒ‡å°–), 19(ç¬¬ä¸‰å…³èŠ‚), 18(ç¬¬äºŒå…³èŠ‚), 17(æ ¹éƒ¨)
        
        # æ£€æŸ¥æ¯ä¸ªæ‰‹æŒ‡æ˜¯å¦ä¼¸ç›´
        thumb_extended = self.get_finger_state(landmarks, 4, 3, 2, 0)
        index_extended = self.get_finger_state(landmarks, 8, 7, 6, 0)
        middle_extended = self.get_finger_state(landmarks, 12, 11, 10, 0)
        ring_extended = self.get_finger_state(landmarks, 16, 15, 14, 0)
        pinky_extended = self.get_finger_state(landmarks, 20, 19, 18, 0)
        
        # åˆ¤æ–­æ˜¯å¦æ˜¯æ¡æ‹³ï¼ˆç¬¬6å¼¦ï¼‰
        # æ¡æ‹³ï¼šæ‰€æœ‰æ‰‹æŒ‡éƒ½ä¸ä¼¸ç›´
        if not (thumb_extended or index_extended or middle_extended or ring_extended or pinky_extended):
            strings.append(6)
        else:
            # æ·»åŠ ä¼¸ç›´æ‰‹æŒ‡å¯¹åº”çš„å¼¦
            if thumb_extended:
                strings.append(1)
            if index_extended:
                strings.append(2)
            if middle_extended:
                strings.append(3)
            if ring_extended:
                strings.append(4)
            if pinky_extended:
                strings.append(5)
        
        return strings
    
    def get_palm_orientation(self, landmarks):
        """åˆ¤æ–­æ‰‹æŒæœå‘ï¼šç«–å‘æˆ–æ¨ªå‘"""
        # è·å–å…³é”®ç‚¹
        wrist = landmarks[0]
        index_mcp = landmarks[5]  # é£ŸæŒ‡æ ¹éƒ¨
        pinky_mcp = landmarks[17] # å°æŒ‡æ ¹éƒ¨
        
        # è®¡ç®—æ‰‹æŒå®½åº¦å‘é‡
        palm_vector = np.array([pinky_mcp.x - index_mcp.x, pinky_mcp.y - index_mcp.y])
        
        # è®¡ç®—ä¸æ°´å¹³çº¿çš„å¤¹è§’
        angle = np.degrees(np.arctan2(abs(palm_vector[1]), abs(palm_vector[0])))
        
        # å¦‚æœå¤¹è§’å¤§äº45åº¦ï¼Œè®¤ä¸ºæ˜¯ç«–å‘ï¼›å¦åˆ™æ˜¯æ¨ªå‘
        if angle > 45:
            return "vertical"
        else:
            return "horizontal"
    
    def detect_right_hand_fret(self, landmarks):
        """æ£€æµ‹å³æ‰‹æ‰‹åŠ¿ï¼Œè¿”å›é€‰æ‹©çš„å“"""
        # å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯æ¡æ‹³ï¼ˆå¼€å§‹æ‰‹åŠ¿ï¼‰
        thumb_extended = self.get_finger_state(landmarks, 4, 3, 2, 0)
        index_extended = self.get_finger_state(landmarks, 8, 7, 6, 0)
        middle_extended = self.get_finger_state(landmarks, 12, 11, 10, 0)
        ring_extended = self.get_finger_state(landmarks, 16, 15, 14, 0)
        pinky_extended = self.get_finger_state(landmarks, 20, 19, 18, 0)
        
        # è·å–æ‰‹æŒæœå‘
        orientation = self.get_palm_orientation(landmarks)
        
        # è®¡ç®—ä¼¸ç›´çš„æ‰‹æŒ‡æ•°
        extended_fingers = []
        if thumb_extended:
            extended_fingers.append("thumb")
        if index_extended:
            extended_fingers.append("index")
        if middle_extended:
            extended_fingers.append("middle")
        if ring_extended:
            extended_fingers.append("ring")
        if pinky_extended:
            extended_fingers.append("pinky")
        
        finger_count = len(extended_fingers)
        
        # æ ¹æ®ä½ çš„è®¾è®¡è§„åˆ™ç¡®å®šå“
        if orientation == "vertical":
            if finger_count == 1:
                # å•ä¸ªæ‰‹æŒ‡ï¼š1-5å“
                return finger_count
            elif finger_count == 2:
                # ç‰¹æ®Šç»„åˆ
                if "thumb" in extended_fingers and "index" in extended_fingers:
                    return 11  # æ‹‡æŒ‡+é£ŸæŒ‡
                elif "thumb" in extended_fingers and "pinky" in extended_fingers:
                    return 12  # æ‹‡æŒ‡+å°æŒ‡
                elif "index" in extended_fingers and "middle" in extended_fingers:
                    return 13  # é£ŸæŒ‡+ä¸­æŒ‡
                elif "index" in extended_fingers and "pinky" in extended_fingers:
                    return 14  # é£ŸæŒ‡+å°æŒ‡
                else:
                    return finger_count  # é»˜è®¤æŒ‰æ‰‹æŒ‡æ•°
            elif 2 <= finger_count <= 5:
                return finger_count
        elif orientation == "horizontal":
            if 1 <= finger_count <= 5:
                return finger_count + 5  # 6-10å“
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œè¿”å›0å“
        return 0
    
    def detect_control_gestures(self, results, frame_shape):
        """æ£€æµ‹æ§åˆ¶æ‰‹åŠ¿"""
        control_action = None
        
        if results.multi_hand_landmarks and results.multi_handedness:
            right_fist = False
            left_fist = False
            
            for idx, hand_landmarks in enumerate(results.multi_hand_landmarks):
                hand_label = results.multi_handedness[idx].classification[0].label
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ¡æ‹³
                thumb_extended = self.get_finger_state(hand_landmarks.landmark, 4, 3, 2, 0)
                index_extended = self.get_finger_state(hand_landmarks.landmark, 8, 7, 6, 0)
                middle_extended = self.get_finger_state(hand_landmarks.landmark, 12, 11, 10, 0)
                ring_extended = self.get_finger_state(hand_landmarks.landmark, 16, 15, 14, 0)
                pinky_extended = self.get_finger_state(hand_landmarks.landmark, 20, 19, 18, 0)
                
                is_fist = not (thumb_extended or index_extended or middle_extended or ring_extended or pinky_extended)
                
                # è·å–æ‰‹è…•ä½ç½®
                wrist = hand_landmarks.landmark[0]
                wrist_y = wrist.y * frame_shape[0]
                
                # å­˜å‚¨æ‰‹éƒ¨ä½ç½®ç”¨äºæ£€æµ‹ä¸Šä¸‹ç§»åŠ¨
                if hand_label == "Left":
                    if "left" not in self.hand_positions:
                        self.hand_positions["left"] = []
                    self.hand_positions["left"].append(wrist_y)
                    if len(self.hand_positions["left"]) > 10:
                        self.hand_positions["left"].pop(0)
                    
                    left_fist = is_fist
                else:  # Right hand
                    if "right" not in self.hand_positions:
                        self.hand_positions["right"] = []
                    self.hand_positions["right"].append(wrist_y)
                    if len(self.hand_positions["right"]) > 10:
                        self.hand_positions["right"].pop(0)
                    
                    right_fist = is_fist
                    
                    # æ£€æµ‹æ‰‹éƒ¨ä¸Šä¸‹ç§»åŠ¨ï¼ˆéŸ³é‡æ§åˆ¶ï¼‰
                    if len(self.hand_positions["right"]) >= 5:
                        # è®¡ç®—æœ€è¿‘5ä¸ªä½ç½®çš„å¹³å‡å˜åŒ–
                        positions = self.hand_positions["right"][-5:]
                        if len(positions) >= 2:
                            change = positions[-1] - positions[0]
                            
                            # å¦‚æœæ‰‹éƒ¨æŒç»­ä¸Šå‡æˆ–ä¸‹é™
                            if change < -20:  # ä¸Šå‡ï¼ˆyå€¼å‡å°ï¼‰
                                control_action = "volume_up"
                            elif change > 20:  # ä¸‹é™ï¼ˆyå€¼å¢åŠ ï¼‰
                                control_action = "volume_down"
            
            # æ£€æµ‹å¼€å§‹/ç»“æŸæ‰‹åŠ¿
            if right_fist and not left_fist:
                control_action = "start"
            elif right_fist and left_fist:
                control_action = "end"
        
        return control_action
    
    def process_frame(self, frame):
        """å¤„ç†ä¸€å¸§å›¾åƒï¼Œè¿”å›è¯†åˆ«ç»“æœ"""
        # è½¬æ¢é¢œè‰²ç©ºé—´
        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        image_rgb.flags.writeable = False
        
        # å¤„ç†å›¾åƒ
        results = self.hands.process(image_rgb)
        
        # è½¬æ¢å›æ¥
        image_rgb.flags.writeable = True
        output_frame = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
        
        # é‡ç½®æ‰‹åŠ¿çŠ¶æ€
        self.left_hand_strings = []
        self.right_hand_fret = 0
        
        # æ£€æµ‹æ§åˆ¶æ‰‹åŠ¿
        control_action = self.detect_control_gestures(results, frame.shape)
        
        # å¤„ç†æ§åˆ¶åŠ¨ä½œ
        if control_action:
            if control_action == "start":
                self.is_recording = True
                print("ğŸ¸ å¼€å§‹æ¼”å¥!")
            elif control_action == "end":
                self.is_recording = False
                print("ğŸ¸ ç»“æŸæ¼”å¥!")
            elif control_action == "volume_up":
                self.volume = min(1.0, self.volume + 0.05)
                print(f"ğŸ”Š éŸ³é‡å¢åŠ : {self.volume:.2f}")
            elif control_action == "volume_down":
                self.volume = max(0.0, self.volume - 0.05)
                print(f"ğŸ”Š éŸ³é‡å‡å°: {self.volume:.2f}")
        
        # åªæœ‰å½“å¼€å§‹åï¼Œæ‰æ£€æµ‹æ¼”å¥æ‰‹åŠ¿
        if self.is_recording and results.multi_hand_landmarks and results.multi_handedness:
            left_detected = False
            right_detected = False
            
            for idx, hand_landmarks in enumerate(results.multi_hand_landmarks):
                hand_label = results.multi_handedness[idx].classification[0].label
                
                # ç»˜åˆ¶æ‰‹éƒ¨å…³é”®ç‚¹
                self.mp_drawing.draw_landmarks(
                    output_frame, hand_landmarks, self.mp_hands.HAND_CONNECTIONS,
                    self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),
                    self.mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2)
                )
                
                # åŒºåˆ†å·¦å³æ‰‹å¹¶è¯†åˆ«æ‰‹åŠ¿
                if hand_label == "Left":
                    self.left_hand_strings = self.detect_left_hand_strings(hand_landmarks.landmark)
                    left_detected = True
                    
                    # åœ¨ç”»é¢ä¸­æ˜¾ç¤ºå·¦æ‰‹é€‰æ‹©çš„å¼¦
                    cv2.putText(output_frame, f"å·¦æ‰‹å¼¦: {self.left_hand_strings}", 
                              (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                else:  # Right hand
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ¡æ‹³ï¼ˆæ§åˆ¶æ‰‹åŠ¿å·²åœ¨å‰é¢å¤„ç†ï¼‰
                    thumb_extended = self.get_finger_state(hand_landmarks.landmark, 4, 3, 2, 0)
                    index_extended = self.get_finger_state(hand_landmarks.landmark, 8, 7, 6, 0)
                    middle_extended = self.get_finger_state(hand_landmarks.landmark, 12, 11, 10, 0)
                    is_fist = not (thumb_extended or index_extended or middle_extended)
                    
                    if not is_fist:  # ä¸æ˜¯æ¡æ‹³æ‰æ£€æµ‹å“
                        self.right_hand_fret = self.detect_right_hand_fret(hand_landmarks.landmark)
                        right_detected = True
                        
                        # åœ¨ç”»é¢ä¸­æ˜¾ç¤ºå³æ‰‹é€‰æ‹©çš„å“
                        cv2.putText(output_frame, f"å³æ‰‹å“: {self.right_hand_fret}", 
                                  (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # å¦‚æœå·¦å³æ‰‹éƒ½æ£€æµ‹åˆ°ï¼Œæ˜¾ç¤ºå’Œå¼¦ä¿¡æ¯
            if left_detected and right_detected and self.left_hand_strings:
                chord_info = f"å’Œå¼¦: å¼¦{self.left_hand_strings}, å“{self.right_hand_fret}"
                cv2.putText(output_frame, chord_info, 
                          (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
                
                # è¿™é‡Œå¯ä»¥æ·»åŠ æ’­æ”¾å’Œå¼¦çš„ä»£ç 
                self.play_chord(self.left_hand_strings, self.right_hand_fret)
        
        # æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯
        status = "å½•åˆ¶ä¸­" if self.is_recording else "ç­‰å¾…å¼€å§‹"
        cv2.putText(output_frame, f"çŠ¶æ€: {status}", 
                   (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
        cv2.putText(output_frame, f"éŸ³é‡: {self.volume:.2f}", 
                   (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
        
        return output_frame, self.left_hand_strings, self.right_hand_fret
    
    def play_chord(self, strings, fret):
        """æ’­æ”¾å’Œå¼¦ï¼ˆè¿™é‡Œéœ€è¦ä½ å®ç°éŸ³é¢‘æ’­æ”¾é€»è¾‘ï¼‰"""
        # è¿™é‡Œåªæ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œä½ éœ€è¦æ ¹æ®ä½ çš„éŸ³é¢‘åº“æ¥å®ç°
        print(f"ğŸµ æ’­æ”¾å’Œå¼¦: å¼¦{strings}, å“{fret}, éŸ³é‡{self.volume}")
        
        # æ ¹æ®å¼¦å’Œå“è®¡ç®—éŸ³é«˜
        # å‰ä»–æ ‡å‡†è°ƒéŸ³ï¼šEADGBE (ä»6å¼¦åˆ°1å¼¦)
        standard_tuning = [40, 45, 50, 55, 59, 64]  # MIDIéŸ³ç¬¦ç¼–å·
        
        notes = []
        for string in strings:
            if 1 <= string <= 6:
                # è®¡ç®—è¯¥å¼¦åœ¨æŒ‡å®šå“çš„éŸ³é«˜
                midi_note = standard_tuning[string-1] + fret
                notes.append(midi_note)
        
        # åœ¨è¿™é‡Œè°ƒç”¨ä½ çš„éŸ³é¢‘æ’­æ”¾å‡½æ•°
        # ä¾‹å¦‚: play_notes(notes, self.volume)
        
    def run(self):
        """è¿è¡Œä¸»å¾ªç¯"""
        cap = cv2.VideoCapture(0)
        
        print("ğŸ¸ ç©ºæ°”å‰ä»–ç³»ç»Ÿå¯åŠ¨!")
        print("æ§åˆ¶æ‰‹åŠ¿:")
        print("  - å³æ‰‹æ¡æ‹³: å¼€å§‹")
        print("  - åŒæ‰‹æ¡æ‹³: ç»“æŸ")
        print("  - æ‰‹ç¼“æ…¢ä¸Šå‡: åŠ å¤§éŸ³é‡")
        print("  - æ‰‹ç¼“æ…¢ä¸‹é™: é™ä½éŸ³é‡")
        print("\næ¼”å¥æ‰‹åŠ¿:")
        print("  - å·¦æ‰‹: æ‰‹æŒ‡ä¼¸ç›´é€‰æ‹©å¼¦ (æ‹‡æŒ‡=1å¼¦, é£ŸæŒ‡=2å¼¦, ä¸­æŒ‡=3å¼¦, æ— åæŒ‡=4å¼¦, å°æŒ‡=5å¼¦, æ¡æ‹³=6å¼¦)")
        print("  - å³æ‰‹: ç«–å‘1-5æŒ‡=1-5å“, æ¨ªå‘1-5æŒ‡=6-10å“")
        print("          ç‰¹æ®Šæ‰‹åŠ¿: æ‹‡æŒ‡+é£ŸæŒ‡=11å“, æ‹‡æŒ‡+å°æŒ‡=12å“, é£ŸæŒ‡+ä¸­æŒ‡=13å“, é£ŸæŒ‡+å°æŒ‡=14å“")
        
        while cap.isOpened():
            success, frame = cap.read()
            if not success:
                print("æ— æ³•è¯»å–æ‘„åƒå¤´")
                break
            
            # å¤„ç†å¸§
            output_frame, strings, fret = self.process_frame(frame)
            
            # æ˜¾ç¤ºç»“æœ
            cv2.imshow('Air Guitar', output_frame)
            
            # æŒ‰ESCé€€å‡º
            if cv2.waitKey(5) & 0xFF == 27:
                break
        
        cap.release()
        cv2.destroyAllWindows()

# è¯¥æ–‡ä»¶åªå¯¼å‡º `AirGuitarGestureRecognizer` ç±»ä¾›ä¸»ç¨‹åºè°ƒç”¨ã€‚
# è‹¥éœ€è¦ç‹¬ç«‹è¿è¡Œè°ƒè¯•ï¼Œè¯·ä½¿ç”¨é¡¹ç›®æä¾›çš„ `debug_hand_test.py` æˆ–ç›´æ¥è¿è¡Œ `main_app.py`ã€‚